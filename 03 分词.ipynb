{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ecdef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from zhon.hanzi import punctuation # 中文标点\n",
    "import jieba\n",
    "import re\n",
    "from bert_serving.client import BertClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # 创建TF-IDF向量化器\n",
    "from cnsenti import Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8122a",
   "metadata": {},
   "source": [
    "——————————————————————————————————————  \n",
    "### 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c3e6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000004</td>\n",
       "      <td>2018</td>\n",
       "      <td>讨论与分析一概述年度，公司实现主营业务收入万元，比上年同期增加，实现归属于上市公司股东的净利...</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000004</td>\n",
       "      <td>2020</td>\n",
       "      <td>讨论与分析一概述年是公司业务转型后的第一年，年，公司筹划发行股份收购智游网安股权的重大资产重...</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     code  year                                               text board\n",
       "0  000004  2018  讨论与分析一概述年度，公司实现主营业务收入万元，比上年同期增加，实现归属于上市公司股东的净利...    00\n",
       "1  000004  2020  讨论与分析一概述年是公司业务转型后的第一年，年，公司筹划发行股份收购智游网安股权的重大资产重...    00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_1820_path ='F:\\\\zzqaq\\\\data\\\\data_clean_2018_2020.csv'\n",
    "text_1820 = pd.read_csv(text_1820_path,encoding=\"gb18030\",converters={'code':str,'year':str,'board':str})\n",
    "text_1820[\"board\"] = [str(i).replace(\"\\t\",\"\") for i in text_1820[\"board\"]]\n",
    "text_1820.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e56bc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数每个文本句子个数\n",
    "sentence_count=[]\n",
    "for i in range(text_1820.shape[0]):\n",
    "    text_split_each = re.split(r'(?:[。?!])', text_1820['text'][i])\n",
    "#     print(i,len(text_split_each))\n",
    "    sentence_count.append(len(text_split_each))\n",
    "# 作为特征放入df\n",
    "text_1820['sentence_count'] = sentence_count\n",
    "all_text_data['word_count']=word_count\n",
    "all_text_data['readability']=all_text_data['word_count']/all_text_data['sentence_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e4dc7c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\asus\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.937 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "# 分词生成语料\n",
    "text_split = list(text_1820['text'])\n",
    "# 每个句子进行分词\n",
    "corpus = []\n",
    "i = 0\n",
    "for text_to_cut in text_split:\n",
    "# # 词语生成器\n",
    "#     print(text_to_cut)\n",
    "    text_to_cut = re.sub(r'[%s]+' %punctuation,\"\", text_to_cut) #去标点    \n",
    "    text_to_cut = re.sub('[a-zA-Z]','',text_to_cut) # 去英文\n",
    "    text_cut = jieba.cut(text_to_cut, cut_all=False)\n",
    "    text_cut  = \" \".join(text_cut)\n",
    "    corpus.append(text_cut)\n",
    "    i+=1\n",
    "    if(i%1000==0):print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "53fa2824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>year</th>\n",
       "      <th>corpus</th>\n",
       "      <th>board</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000004</td>\n",
       "      <td>2018</td>\n",
       "      <td>讨论 分析 概述 年度 实现 主营业务 收入 万元 上年 同期 增加 实现 归属于 上市公司...</td>\n",
       "      <td>00</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000004</td>\n",
       "      <td>2020</td>\n",
       "      <td>讨论 分析 概述 年 业务 转型 后 第一年 年 筹划 发行 股份 收购 智游 网安 股权 ...</td>\n",
       "      <td>00</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000005</td>\n",
       "      <td>2018</td>\n",
       "      <td>讨论 分析 概述 报告 期内 本司 主营业务 架构 调整 如下 交通 清洁 能源 水资源 基...</td>\n",
       "      <td>00</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     code  year                                             corpus board  \\\n",
       "0  000004  2018  讨论 分析 概述 年度 实现 主营业务 收入 万元 上年 同期 增加 实现 归属于 上市公司...    00   \n",
       "1  000004  2020  讨论 分析 概述 年 业务 转型 后 第一年 年 筹划 发行 股份 收购 智游 网安 股权 ...    00   \n",
       "2  000005  2018  讨论 分析 概述 报告 期内 本司 主营业务 架构 调整 如下 交通 清洁 能源 水资源 基...    00   \n",
       "\n",
       "   sentence_count  \n",
       "0              52  \n",
       "1             126  \n",
       "2             122  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看\n",
    "text_1820.text = corpus\n",
    "# text_1820.head(2)\n",
    "\n",
    "# 去停用词\n",
    "path_stpwrd = 'F:\\\\zzqaq\\\\text_data_processs\\\\哈工大停用词表.txt'\n",
    "with open(path_stpwrd, 'rb') as fp:\n",
    "    stopword = fp.read().decode('utf-8')  # 提用词提取\n",
    "stpwrdlst = stopword.splitlines()  #将停用词表转换为list  \n",
    "extra_stpwrd=['巨潮','资讯网','√','□','公司','年度报告']\n",
    "stpwrdlst_ = stpwrdlst + extra_stpwrd\n",
    "\n",
    "new_corpus = []\n",
    "\n",
    "for string in corpus:\n",
    "    words = [word for word in string.split() if word not in stpwrdlst_]\n",
    "    new_string = ' '.join(words)\n",
    "    new_corpus.append(new_string)\n",
    "\n",
    "# 查看\n",
    "text_1820['text'] = new_corpus\n",
    "text_1820=text_1820.rename(columns={'text':'corpus'})\n",
    "text_1820.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782488ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "text_1820.to_csv('F:\\\\zzqaq\\\\data\\\\corpus_2018_2020.csv',encoding=\"gb18030\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f64c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取\n",
    "corpus_18_20_path ='F:\\\\zzqaq\\\\data\\\\corpus_2018_2020.csv'\n",
    "corpus_1820 = pd.read_csv(corpus_18_20_path,encoding=\"gb18030\",converters={'code':str,'year':str,'board':str})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
